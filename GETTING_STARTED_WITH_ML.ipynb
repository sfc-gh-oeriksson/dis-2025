{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "lastEditStatus": {
   "notebookId": "bpyukpv72fgrmrrq6f2o",
   "authorId": "6967281494909",
   "authorName": "OSKAR",
   "authorEmail": "oskar.eriksson@snowflake.com",
   "sessionId": "41bec393-69ea-4def-81ba-77b28bf99389",
   "lastEditTime": 1746534360021
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92e32af2-b6bf-4086-a361-93e61b633d44",
   "metadata": {
    "name": "md_env",
    "collapsed": false,
    "resultHeight": 157
   },
   "source": "# IMPORTANT \nMake sure you've imported the [environment.yml](https://github.com/Snowflake-Labs/sfguide-intro-to-machine-learning-with-snowflake-ml-for-python/blob/main/notebooks/environment.yml) file provided in the git repo on the left sidebar.\n\nThis will ensure if you have the right packages needed to run this Notebook."
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f4adaa3-8ef6-4c8f-8057-1d12bf900962",
   "metadata": {
    "name": "md_data_ingest",
    "resultHeight": 179,
    "collapsed": false
   },
   "source": [
    "## 1. Data Ingestion\n",
    "\n",
    "The `diamonds` dataset has been widely used in data science and machine learning. We will use it to demonstrate Snowflake's native data science transformers in terms of database functionality and Spark & Pandas comportablity, using non-synthetic and statistically appropriate data that is well known to the ML community.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fe2a4b4-821f-410c-8d2c-e527829b106e",
   "metadata": {
    "name": "md_import_libs",
    "resultHeight": 46
   },
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed4494-06ab-43b2-86e8-879c99c1a2c0",
   "metadata": {
    "language": "python",
    "name": "import_libs",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# Snowpark for Python\n#from snowflake.snowpark.types import DoubleType\n#from snowflake.snowpark.types import DecimalType\n\nimport snowflake.snowpark.functions as F\nimport streamlit as st\n\n# Snowflake Cortex (Generative AI)\nfrom snowflake.cortex import complete\n\n\n# Snowflake ML\nimport snowflake.ml.modeling.preprocessing as snowml\nfrom snowflake.ml.modeling.pipeline import Pipeline\nfrom snowflake.ml.modeling.metrics.correlation import correlation\nfrom snowflake.ml.modeling.xgboost import XGBRegressor\nfrom snowflake.ml.registry import Registry\nfrom snowflake.ml._internal.utils import identifier\nfrom snowflake.ml.modeling.metrics import mean_absolute_percentage_error\n\n\n# OSS data analysis\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Misc\n#import json\n#import joblib\n\n# warning suppresion\nimport warnings; warnings.simplefilter('ignore')"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39326625-0d17-438f-a847-8d1e2c1488da",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "name": "md_active_session",
    "resultHeight": 113
   },
   "source": "### Setup context just to be sure (Compute, DB, Schema)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76605036-bbf0-45cd-ac16-8c7bb391384c",
   "metadata": {
    "language": "sql",
    "name": "init_sql",
    "resultHeight": 87
   },
   "outputs": [],
   "source": [
    "-- Using Warehouse, Database, and Schema created during Setup\n",
    "USE WAREHOUSE ML_HOL_WH;\n",
    "USE DATABASE ML_HOL_DB;\n",
    "USE SCHEMA ML_HOL_SCHEMA;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046fa3ea-5ea9-4af6-a4dd-88c7101dcf0d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "language": "python",
    "name": "get_active_session",
    "resultHeight": 150
   },
   "outputs": [],
   "source": [
    "# Get Snowflake Session object\n",
    "session = get_active_session()\n",
    "session.sql_simplifier_enabled = True\n",
    "\n",
    "# Add a query tag to the session.\n",
    "session.query_tag = {\"origin\":\"sf_sit-is\", \n",
    "                     \"name\":\"e2e_ml_snowparkpython\", \n",
    "                     \"version\":{\"major\":1, \"minor\":0,},\n",
    "                     \"attributes\":{\"is_quickstart\":1}}\n",
    "\n",
    "# Current Environment Details\n",
    "print('Connection Established with the following parameters:')\n",
    "print('User      : {}'.format(session.get_current_user()))\n",
    "print('Role      : {}'.format(session.get_current_role()))\n",
    "print('Database  : {}'.format(session.get_current_database()))\n",
    "print('Schema    : {}'.format(session.get_current_schema()))\n",
    "print('Warehouse : {}'.format(session.get_current_warehouse()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9f22ce6-da50-4d76-98e1-3ff6246ed220",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "name": "md_read_diamonds",
    "resultHeight": 153
   },
   "source": [
    "### Use the Snowpark DataFrame Reader to read in data from the externally staged `diamonds` CSV file \n",
    "\n",
    "In setup.sql, we staged the `diamonds.csv` file from an external s3 bucket. Now, we can read it in.\n",
    "\n",
    "For more information on loading data, see documentation on [snowflake.snowpark.DataFrameReader](https://docs.snowflake.com/ko/developer-guide/snowpark/reference/python/api/snowflake.snowpark.DataFrameReader.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080dc92-595e-48b6-b4fc-667e2346bed9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "language": "python",
    "name": "read_diamonds",
    "resultHeight": 439
   },
   "outputs": [],
   "source": [
    "# Create a Snowpark DataFrame that is configured to load data from the CSV file\n",
    "# We can now infer schema from CSV files.\n",
    "diamonds_df = session.read.options({\"field_delimiter\": \",\",\n",
    "                                    \"field_optionally_enclosed_by\": '\"',\n",
    "                                    \"infer_schema\": True,\n",
    "                                    \"parse_header\": True}).csv(\"@DIAMONDS_ASSETS\")\n",
    "\n",
    "diamonds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f72db-d8b4-4f25-aaf0-928475009895",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "describe_diamonds",
    "resultHeight": 252
   },
   "outputs": [],
   "source": [
    "# Look at descriptive stats on the DataFrame\n",
    "diamonds_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8205f888-1a4a-4033-b4f4-ddbb1bc30e67",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "diamonds_cols",
    "resultHeight": 360
   },
   "outputs": [],
   "source": [
    "diamonds_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd0ce8f-0f7d-4cc9-ad07-f59d5c8e67a2",
   "metadata": {
    "language": "python",
    "name": "uppercase_headers",
    "resultHeight": 439
   },
   "outputs": [],
   "source": [
    "# Force headers to uppercase\n",
    "for colname in diamonds_df.columns:\n",
    "    if colname == '\"table\"':\n",
    "       new_colname = \"TABLE_PCT\"\n",
    "    else:\n",
    "        new_colname = str.upper(colname)\n",
    "    diamonds_df = diamonds_df.with_column_renamed(colname, new_colname)\n",
    "\n",
    "diamonds_df"
   ]
  },
  {
   "cell_type": "code",
   "id": "f212cef2-e2f8-4305-81f6-482f4c8c638e",
   "metadata": {
    "language": "python",
    "name": "use_llm_for_inspo"
   },
   "outputs": [],
   "source": "llm = 'claude-3-5-sonnet'\n\nprompt = f\"\"\"\nI used Snowparks describe function to calculate count, mean, stddev, min and max per column.\nI want to build a machine learning model using both numeric and categorical features to predict PRICE.\nWhat feature engineering steps should I perform based on their statistics from describe()? \nProvide a short Python code that does it for me.\n\nThe dataframe:\n{diamonds_df.describe().to_pandas().to_markdown()}\n\"\"\"\n\nresponse = complete(llm, prompt)\nst.markdown(response)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "51eedd10-1463-4e59-babe-2e0114f036c4",
   "metadata": {
    "language": "python",
    "name": "convert_to_pandas"
   },
   "outputs": [],
   "source": "diamonds_pdf = diamonds_df.to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d095e387-fb6b-4546-9a83-634c52a46236",
   "metadata": {
    "language": "python",
    "name": "data_prep_and_feature_engineering"
   },
   "outputs": [],
   "source": "import pandas as pd\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder\nfrom sklearn.compose import ColumnTransformer\nimport numpy as np\n\ndef engineer_features(diamonds_pdf):\n    # 1. Handle outliers in dimensions (X, Y, Z)\n    dimension_cols = ['X', 'Y', 'Z']\n    df = diamonds_pdf[~(diamonds_pdf[dimension_cols] == 0).any(axis=1)]  # Remove 0 dimensions\n    \n    # 2. Create interaction features\n    df['VOLUME'] = df['X'] * df['Y'] * df['Z']\n    df['RATIO'] = df['X'] / df['Y']  # length/width ratio\n    \n    # 3. Define feature groups\n    numeric_features = ['CARAT', 'DEPTH', 'TABLE_PCT', 'X', 'Y', 'Z', 'VOLUME', 'RATIO']\n    categorical_features = ['CUT', 'COLOR', 'CLARITY']\n    \n    # 4. Create ordinal mappings for categorical features\n    cut_order = ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal']\n    color_order = ['J', 'I', 'H', 'G', 'F', 'E', 'D']  # D is best\n    clarity_order = ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']  # IF is best\n    \n    # 5. Create preprocessing pipeline\n    preprocessor = ColumnTransformer(\n        transformers=[\n            ('num', StandardScaler(), numeric_features),\n            ('cat', OrdinalEncoder(categories=[cut_order, color_order, clarity_order]), \n             categorical_features)\n        ])\n    \n    # Store the PRICE column before transformation\n    price = df['PRICE'].copy()\n    \n    # 6. Fit and transform the data\n    df_transformed = preprocessor.fit_transform(df)\n    \n    # Create new dataframe with transformed features\n    feature_names = (numeric_features + \n                    [f\"{feat}_ENCODED\" for feat in categorical_features])\n    df_transformed = pd.DataFrame(\n        df_transformed, \n        columns=feature_names\n    )\n    \n    # Add back the PRICE column to the transformed dataframe\n    df_transformed['PRICE'] = price.values\n    \n    return df_transformed, preprocessor\n\ndf_transformed, preprocessor = engineer_features(diamonds_pdf)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f581873f-1e27-4550-80c8-04e9fc4e7372",
   "metadata": {
    "language": "python",
    "name": "write_to_temp_table"
   },
   "outputs": [],
   "source": "session.write_pandas(df_transformed,auto_create_table=True,table_type='temp',table_name='DIAMONDS_PREP',overwrite=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0e5f852d-8087-4e62-b1f1-1342e51dc856",
   "metadata": {
    "language": "python",
    "name": "read_as_snowpark_dataframe"
   },
   "outputs": [],
   "source": "spdf = session.table('diamonds_prep')\nspdf.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0d00d0c5-157e-461b-b3e7-6577e081935d",
   "metadata": {
    "name": "md_time_for_ml",
    "collapsed": false
   },
   "source": "# Time to prepare for machine learning!"
  },
  {
   "cell_type": "code",
   "id": "2d2f2f4e-3388-4faa-9f00-cd3de71bc22e",
   "metadata": {
    "language": "python",
    "name": "distributed_correlation_analysis"
   },
   "outputs": [],
   "source": "corr_diamonds_df = correlation(df=spdf)\ncorr_diamonds_df # This is a Pandas DataFrame",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "530991e3-8676-4f31-b382-d5e1bc221d0a",
   "metadata": {
    "language": "python",
    "name": "visualize_correlation"
   },
   "outputs": [],
   "source": "# # Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr_diamonds_df, dtype=bool))\n\n# # Create a heatmap with the features\nplt.figure(figsize=(7, 7))\nheatmap = sns.heatmap(corr_diamonds_df, mask=mask, cmap=\"YlGnBu\", annot=True, vmin=-1, vmax=1)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ff96110e-4a93-4b3b-a6c9-65e697eeb15e",
   "metadata": {
    "language": "python",
    "name": "price_carat_visualization"
   },
   "outputs": [],
   "source": "# Set up a plot to look at CARAT and PRICE\ncounts = spdf.to_pandas().groupby(['PRICE', 'CARAT', 'CLARITY_ENCODED']).size().reset_index(name='Count')\n\nfig, ax = plt.subplots(figsize=(20, 20))\nplt.title('Price vs Carat', fontsize=28)\nax = sns.scatterplot(data=counts, x='CARAT', y='PRICE', size='Count', hue='CLARITY_ENCODED', markers='o')\nax.grid(axis='y')\n\n# The relationship is not linear - it appears exponential which makes sense given the rarity of the large diamonds\nsns.move_legend(ax, \"upper left\")\nsns.despine(left=True, bottom=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "573a76a8-a89e-41de-a321-464a95dfcac9",
   "metadata": {
    "language": "python",
    "name": "train_test_split",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Split the data into train and test sets\ndiamonds_train_df, diamonds_test_df = spdf.random_split(weights=[0.9, 0.1], seed=0)\ndiamonds_train_df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "da8eac14-b80a-46d2-ada7-05be22f931d9",
   "metadata": {
    "language": "python",
    "name": "get_input_cols",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "INPUT_COLS = [col for col in spdf.columns if col != 'PRICE']\nINPUT_COLS",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a7d028bb-3b8e-455e-90ca-872e8c8666df",
   "metadata": {
    "language": "python",
    "name": "get_label_col"
   },
   "outputs": [],
   "source": "LABEL_COLUMN = ['PRICE']\nLABEL_COLUMN",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "88489558-5760-4b47-8349-e7bec5928ae8",
   "metadata": {
    "language": "python",
    "name": "get_output_col"
   },
   "outputs": [],
   "source": "OUTPUT_COLUMN = ['PREDICTED_PRICE']\nOUTPUT_COLUMN",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94088d8a-9bb1-4eed-bcf4-d71e4eba275d",
   "metadata": {
    "language": "python",
    "name": "train_model"
   },
   "outputs": [],
   "source": "# Define the XGBRegressor\nregressor = XGBRegressor(\n    input_cols=INPUT_COLS,\n    label_cols=LABEL_COLUMN,\n    output_cols=OUTPUT_COLUMN\n)\n\n# Train\nregressor.fit(diamonds_train_df)\n\n# Predict\nresult = regressor.predict(diamonds_test_df)\nresult",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e43aca9e-769c-4bc0-bf7e-b4924c2b458b",
   "metadata": {
    "language": "python",
    "name": "distributed_mape_calculation"
   },
   "outputs": [],
   "source": "mape = mean_absolute_percentage_error(df=result, \n                                        y_true_col_names=\"PRICE\", \n                                        y_pred_col_names=\"PREDICTED_PRICE\")\nmape",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "43d13524-0083-4939-9ddf-491e6b96feba",
   "metadata": {
    "language": "python",
    "name": "plot_accuracy"
   },
   "outputs": [],
   "source": "# Plot actual vs predicted \ng = sns.relplot(data=result[\"PRICE\", \"PREDICTED_PRICE\"].to_pandas().astype(\"float64\"), x=\"PRICE\", y=\"PREDICTED_PRICE\", kind=\"scatter\")\ng.ax.axline((0,0), slope=1, color=\"r\")\n\nplt.show()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "370a4bc3-5c35-4bb4-b163-9e87bf2fe7b6",
   "metadata": {
    "name": "md_model_management",
    "collapsed": false
   },
   "source": "## Now let's put this model in the Model Registry for model management and governance"
  },
  {
   "cell_type": "code",
   "id": "2930ea94-f650-446c-9019-9f98b13c637e",
   "metadata": {
    "language": "python",
    "name": "log_in_registry"
   },
   "outputs": [],
   "source": "# Get sample input data to pass into the registry logging function\nX = diamonds_train_df.select(INPUT_COLS).limit(100)\n\ndb = identifier._get_unescaped_name(session.get_current_database())\nschema = identifier._get_unescaped_name(session.get_current_schema())\n\n# Define model name\nmodel_name = \"DIAMONDS_PRICE_PREDICTION\"\n\n# Create a registry and log the model\nnative_registry = Registry(session=session, database_name=db, schema_name=schema)\n\n# Let's first log the very first model we trained\nmodel_ver = native_registry.log_model(\n    model_name=model_name,\n    model=regressor,\n    sample_input_data=X, # to provide the feature schema\n    options={\"enable_explainability\": True}\n)\n\n# Add evaluation metric\nmodel_ver.set_metric(metric_name=\"mean_abs_pct_err\", value=mape)\n\n# Add a description\nmodel_ver.comment = \"This is the first iteration of our Diamonds Price Prediction model. It is used for demo purposes.\"\n\nmodel_ver",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a847bb30-164e-40f3-9777-92cc1a5ded05",
   "metadata": {
    "name": "md_model_inference",
    "collapsed": false
   },
   "source": "#### List models in registry, then load a model version and make predictions"
  },
  {
   "cell_type": "code",
   "id": "aea2a859-4830-48b0-ad6f-60fa57c5d505",
   "metadata": {
    "language": "python",
    "name": "show_models_in_registry"
   },
   "outputs": [],
   "source": "native_registry.show_models()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a88499fe-dd7d-48e0-b2a6-c100e7e1945d",
   "metadata": {
    "language": "python",
    "name": "show_specific_model"
   },
   "outputs": [],
   "source": "model = native_registry.get_model('DIAMONDS_PRICE_PREDICTION')\nmodel",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "59481734-886c-4d12-a102-8f3057c41fc3",
   "metadata": {
    "language": "python",
    "name": "list_model_versions"
   },
   "outputs": [],
   "source": "model.show_versions()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b4e4523-8a96-4ac9-8309-1e085ce014ac",
   "metadata": {
    "language": "python",
    "name": "get_model_version"
   },
   "outputs": [],
   "source": "model_version = model.version(\"DEFAULT\")\nmodel_version",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1aae3b8-6141-45aa-91ad-ea0a4e7d15e7",
   "metadata": {
    "language": "python",
    "name": "show_model_functions"
   },
   "outputs": [],
   "source": "model_version.show_functions()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "88d3dc6b-5ba4-4e9b-aa7c-1464671a8b4d",
   "metadata": {
    "language": "python",
    "name": "run_inference"
   },
   "outputs": [],
   "source": "preds = model_version.run(diamonds_test_df, function_name='PREDICT')\npreds",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "80fa71de-c815-4b55-9765-3af133f56157",
   "metadata": {
    "language": "python",
    "name": "run_inference_with_explanations"
   },
   "outputs": [],
   "source": "preds_with_explanations = model_version.run(diamonds_test_df, function_name='EXPLAIN')\npreds_with_explanations",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "76bcd2ce-a5ca-45ff-8b32-8fbb74522e75",
   "metadata": {
    "language": "python",
    "name": "visualize_feature_impact"
   },
   "outputs": [],
   "source": "import shap\n\nexplanation_columns = [col for col in preds_with_explanations.columns if 'explanation' in col.lower()]\nexplanation_df = preds_with_explanations[explanation_columns].to_pandas()\n\n\nshap_exp = shap._explanation.Explanation(explanation_df.values, feature_names = explanation_df.columns) # wrapping them into a SHAP recognized object\nshap.plots.bar(shap_exp)",
   "execution_count": null
  }
 ]
}