{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blue-Green Model Deployments for Zero-Downtime Updates\n",
    "\n",
    "This notebook demonstrates how to implement blue-green deployment patterns in Snowflake for ML models, enabling:\n",
    "- Zero-downtime model updates\n",
    "- Safe rollback mechanisms  \n",
    "- A/B testing between model versions\n",
    "- Production-grade MLOps workflows\n",
    "\n",
    "## Why Blue-Green Deployments?\n",
    "\n",
    "Traditional model deployments often require downtime or risk serving inconsistent predictions. Blue-green deployments solve this by:\n",
    "1. **Blue Environment**: Current production model serving live traffic\n",
    "2. **Green Environment**: New model version being deployed and tested\n",
    "3. **Instant Switch**: Traffic routing changes instantly between environments\n",
    "4. **Quick Rollback**: Immediate return to previous version if issues arise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Prerequisites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oeriksson/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'snowflake.ml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import required libraries\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msnowpark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Registry\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msnowflake\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'snowflake.ml'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "from snowflake.ml.modeling.linear_model import LinearRegression\n",
    "from snowflake.ml._internal.utils import identifier\n",
    "from snowflake.ml.modeling.metrics import mean_absolute_percentage_error\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Get session\n",
    "session = get_active_session()\n",
    "session.sql_simplifier_enabled = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Blue-Green Infrastructure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create blue-green deployment infrastructure using Snowpark for Python\n",
    "from snowflake.snowpark.types import StructType, StructField, StringType, BooleanType, TimestampType, DecimalType, FloatType, IntegerType, VariantType\n",
    "\n",
    "# Create deployment management schema\n",
    "session.sql(\"CREATE SCHEMA IF NOT EXISTS ML_HOL_DB.DEPLOYMENT_MANAGEMENT\").collect()\n",
    "session.use_schema(\"ML_HOL_DB.DEPLOYMENT_MANAGEMENT\")\n",
    "\n",
    "# Table creation functions using SQL DDL (which supports DEFAULT values)\n",
    "def create_deployment_tables():\n",
    "    \"\"\"Create deployment tables with proper default values using SQL DDL\"\"\"\n",
    "    \n",
    "    # Create DEPLOYMENT_CONFIG table with defaults\n",
    "    session.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE DEPLOYMENT_CONFIG (\n",
    "        MODEL_NAME STRING,\n",
    "        ENVIRONMENT STRING,  -- 'BLUE' or 'GREEN'\n",
    "        MODEL_VERSION STRING,\n",
    "        IS_ACTIVE BOOLEAN,\n",
    "        DEPLOYMENT_TIME TIMESTAMP_LTZ,\n",
    "        HEALTH_CHECK_STATUS STRING,\n",
    "        TRAFFIC_PERCENTAGE NUMBER(5,2) DEFAULT 0,\n",
    "        CREATED_AT TIMESTAMP_LTZ DEFAULT CURRENT_TIMESTAMP()\n",
    "    )\n",
    "    \"\"\").collect()\n",
    "    \n",
    "    # Create MODEL_PERFORMANCE_METRICS table with defaults\n",
    "    session.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE MODEL_PERFORMANCE_METRICS (\n",
    "        MODEL_NAME STRING,\n",
    "        ENVIRONMENT STRING,\n",
    "        MODEL_VERSION STRING,\n",
    "        METRIC_NAME STRING,\n",
    "        METRIC_VALUE FLOAT,\n",
    "        SAMPLE_SIZE NUMBER,\n",
    "        MEASUREMENT_TIME TIMESTAMP_LTZ DEFAULT CURRENT_TIMESTAMP()\n",
    "    )\n",
    "    \"\"\").collect()\n",
    "    \n",
    "    # Create PREDICTION_REQUESTS table with defaults\n",
    "    session.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE PREDICTION_REQUESTS (\n",
    "        REQUEST_ID STRING,\n",
    "        MODEL_NAME STRING,\n",
    "        ENVIRONMENT STRING,\n",
    "        MODEL_VERSION STRING,\n",
    "        INPUT_DATA VARIANT,\n",
    "        PREDICTION FLOAT,\n",
    "        RESPONSE_TIME_MS NUMBER,\n",
    "        REQUEST_TIME TIMESTAMP_LTZ DEFAULT CURRENT_TIMESTAMP()\n",
    "    )\n",
    "    \"\"\").collect()\n",
    "\n",
    "# Create all deployment tables\n",
    "create_deployment_tables()\n",
    "\n",
    "# Verify table creation using Snowpark DataFrames\n",
    "deployment_config_table = session.table(\"DEPLOYMENT_CONFIG\")\n",
    "performance_metrics_table = session.table(\"MODEL_PERFORMANCE_METRICS\")\n",
    "prediction_requests_table = session.table(\"PREDICTION_REQUESTS\")\n",
    "\n",
    "print(\"‚úÖ Blue-green deployment infrastructure created successfully!\")\n",
    "print(f\"üìã Created tables:\")\n",
    "print(f\"   ‚Ä¢ DEPLOYMENT_CONFIG ({len(deployment_config_table.columns)} columns)\")\n",
    "print(f\"   ‚Ä¢ MODEL_PERFORMANCE_METRICS ({len(performance_metrics_table.columns)} columns)\")\n",
    "print(f\"   ‚Ä¢ PREDICTION_REQUESTS ({len(prediction_requests_table.columns)} columns)\")\n",
    "print(\"üéØ All tables include proper DEFAULT value constraints\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Training Data and Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the diamonds dataset (from the main ML notebook)\n",
    "diamonds_df = session.read.options({\n",
    "    \"field_delimiter\": \",\",\n",
    "    \"field_optionally_enclosed_by\": '\"',\n",
    "    \"infer_schema\": True,\n",
    "    \"parse_header\": True\n",
    "}).csv(\"@ML_HOL_DB.ML_HOL_SCHEMA.DIAMONDS_ASSETS\")\n",
    "\n",
    "# Clean column names\n",
    "for colname in diamonds_df.columns:\n",
    "    if colname == '\"table\"':\n",
    "        new_colname = \"TABLE_PCT\"\n",
    "    else:\n",
    "        new_colname = str.upper(colname)\n",
    "    diamonds_df = diamonds_df.with_column_renamed(colname, new_colname)\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = diamonds_df.random_split(weights=[0.8, 0.2], seed=42)\n",
    "\n",
    "INPUT_COLS = ['CARAT', 'DEPTH', 'TABLE_PCT', 'X', 'Y', 'Z']\n",
    "LABEL_COL = 'PRICE'\n",
    "\n",
    "print(f\"Training data: {train_df.count()} rows\")\n",
    "print(f\"Test data: {test_df.count()} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy Blue Environment (Current Production Model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the \"blue\" model (current production model - simpler baseline)\n",
    "blue_model = LinearRegression(\n",
    "    input_cols=INPUT_COLS,\n",
    "    label_cols=[LABEL_COL],\n",
    "    output_cols=['PREDICTED_PRICE']\n",
    ")\n",
    "\n",
    "print(\"üîµ Training Blue model (Linear Regression)...\")\n",
    "blue_model.fit(train_df)\n",
    "\n",
    "# Test blue model performance\n",
    "blue_predictions = blue_model.predict(test_df)\n",
    "blue_mape = mean_absolute_percentage_error(\n",
    "    df=blue_predictions,\n",
    "    y_true_col_names=LABEL_COL,\n",
    "    y_pred_col_names='PREDICTED_PRICE'\n",
    ")\n",
    "\n",
    "print(f\"üîµ Blue model MAPE: {blue_mape:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create required tags before model registration\n",
    "print(\"üè∑Ô∏è  Creating Snowflake tags for model metadata...\")\n",
    "\n",
    "# Create tags in the DEPLOYMENT_MANAGEMENT schema\n",
    "tag_creation_sql = \"\"\"\n",
    "-- Create tags for model tracking\n",
    "CREATE TAG IF NOT EXISTS ML_HOL_DB.DEPLOYMENT_MANAGEMENT.ENVIRONMENT\n",
    "    COMMENT = 'Deployment environment: blue, green, canary, etc.';\n",
    "\n",
    "CREATE TAG IF NOT EXISTS ML_HOL_DB.DEPLOYMENT_MANAGEMENT.MODEL_TYPE\n",
    "    COMMENT = 'Type of ML model: linear_regression, xgboost, etc.';\n",
    "\n",
    "CREATE TAG IF NOT EXISTS ML_HOL_DB.DEPLOYMENT_MANAGEMENT.STAGE\n",
    "    COMMENT = 'Deployment stage: development, staging, production, canary';\n",
    "\"\"\"\n",
    "\n",
    "session.sql(tag_creation_sql).collect()\n",
    "print(\"‚úÖ Tags created successfully\")\n",
    "\n",
    "# Register blue model in registry\n",
    "db = identifier._get_unescaped_name(session.get_current_database())\n",
    "schema = \"DEPLOYMENT_MANAGEMENT\"\n",
    "registry = Registry(session=session, database_name=db, schema_name=schema)\n",
    "\n",
    "model_name = \"DIAMONDS_PRICE_PREDICTOR\"\n",
    "X_sample = train_df.select(INPUT_COLS).limit(100)\n",
    "\n",
    "# Log blue model (without tags parameter)\n",
    "blue_model_ver = registry.log_model(\n",
    "    model_name=model_name,\n",
    "    version_name=\"BLUE_V1\",\n",
    "    model=blue_model,\n",
    "    sample_input_data=X_sample\n",
    ")\n",
    "\n",
    "blue_model_ver.set_metric(\"mape\", blue_mape)\n",
    "blue_model_ver.comment = \"Blue environment - Production baseline model\"\n",
    "\n",
    "# Add tags to the model (not the version)\n",
    "model = registry.get_model(model_name)\n",
    "model.set_tag(\"ML_HOL_DB.DEPLOYMENT_MANAGEMENT.ENVIRONMENT\", \"blue\")\n",
    "model.set_tag(\"ML_HOL_DB.DEPLOYMENT_MANAGEMENT.MODEL_TYPE\", \"linear_regression\")\n",
    "model.set_tag(\"ML_HOL_DB.DEPLOYMENT_MANAGEMENT.STAGE\", \"production\")\n",
    "\n",
    "print(f\"üîµ Blue model registered: {blue_model_ver.version_name}\")\n",
    "print(\"üîµ Tags added: environment=blue, model_type=linear_regression, stage=production\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update deployment configuration for blue environment\n",
    "session.sql(f\"\"\"\n",
    "INSERT INTO DEPLOYMENT_CONFIG \n",
    "(MODEL_NAME, ENVIRONMENT, MODEL_VERSION, IS_ACTIVE, DEPLOYMENT_TIME, HEALTH_CHECK_STATUS, TRAFFIC_PERCENTAGE)\n",
    "VALUES \n",
    "('{model_name}', 'BLUE', 'BLUE_V1', TRUE, CURRENT_TIMESTAMP(), 'HEALTHY', 100.0)\n",
    "\"\"\")\n",
    "\n",
    "print(\"üîµ Blue environment is now serving 100% of production traffic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Green Environment (New Model Version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the \"green\" model (new improved model)\n",
    "green_model = XGBRegressor(\n",
    "    input_cols=INPUT_COLS,\n",
    "    label_cols=[LABEL_COL],\n",
    "    output_cols=['PREDICTED_PRICE'],\n",
    "    n_estimators=100,\n",
    "    max_depth=6\n",
    ")\n",
    "\n",
    "print(\"üü¢ Training Green model (XGBoost)...\")\n",
    "green_model.fit(train_df)\n",
    "\n",
    "# Test green model performance\n",
    "green_predictions = green_model.predict(test_df)\n",
    "green_mape = mean_absolute_percentage_error(\n",
    "    df=green_predictions,\n",
    "    y_true_col_names=LABEL_COL,\n",
    "    y_pred_col_names='PREDICTED_PRICE'\n",
    ")\n",
    "\n",
    "print(f\"üü¢ Green model MAPE: {green_mape:.4f}\")\n",
    "print(f\"üìä Improvement over Blue: {((blue_mape - green_mape) / blue_mape * 100):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register green model (without tags parameter)\n",
    "green_model_ver = registry.log_model(\n",
    "    model_name=model_name,\n",
    "    version_name=\"GREEN_V2\",\n",
    "    model=green_model,\n",
    "    sample_input_data=X_sample\n",
    ")\n",
    "\n",
    "green_model_ver.set_metric(\"mape\", green_mape)\n",
    "green_model_ver.comment = \"Green environment - Improved XGBoost model\"\n",
    "\n",
    "# Update model tags using fully qualified tag names\n",
    "model = registry.get_model(model_name)\n",
    "model.set_tag(\"ML_HOL_DB.DEPLOYMENT_MANAGEMENT.ENVIRONMENT\", \"green\")   # Updates environment tag\n",
    "model.set_tag(\"ML_HOL_DB.DEPLOYMENT_MANAGEMENT.MODEL_TYPE\", \"xgboost\")  # Updates model_type tag  \n",
    "model.set_tag(\"ML_HOL_DB.DEPLOYMENT_MANAGEMENT.STAGE\", \"canary\")        # Updates stage tag\n",
    "\n",
    "print(f\"üü¢ Green model registered: {green_model_ver.version_name}\")\n",
    "print(\"üü¢ Tags updated: environment=green, model_type=xgboost, stage=canary\")\n",
    "\n",
    "# Deploy to green environment (initially inactive)\n",
    "session.sql(f\"\"\"\n",
    "INSERT INTO DEPLOYMENT_CONFIG \n",
    "(MODEL_NAME, ENVIRONMENT, MODEL_VERSION, IS_ACTIVE, DEPLOYMENT_TIME, HEALTH_CHECK_STATUS, TRAFFIC_PERCENTAGE)\n",
    "VALUES \n",
    "('{model_name}', 'GREEN', 'GREEN_V2', FALSE, CURRENT_TIMESTAMP(), 'HEALTHY', 0.0)\n",
    "\"\"\")\n",
    "\n",
    "print(\"üü¢ Green environment deployed but not yet serving traffic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Canary Deployment (Gradual Traffic Shift)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy import stats\n",
    "from typing import Dict, List, Tuple\n",
    "import uuid\n",
    "\n",
    "class AdvancedCanaryDeployment:\n",
    "    \"\"\"Advanced canary deployment with comprehensive testing and monitoring\"\"\"\n",
    "    \n",
    "    def __init__(self, session, model_name, blue_model, green_model, test_data):\n",
    "        self.session = session\n",
    "        self.model_name = model_name\n",
    "        self.blue_model = blue_model\n",
    "        self.green_model = green_model\n",
    "        self.test_data = test_data\n",
    "        self.metrics_history = []\n",
    "        self.rollback_triggers = {\n",
    "            'error_rate_threshold': 0.05,  # 5% error rate\n",
    "            'latency_degradation': 1.5,    # 50% latency increase\n",
    "            'accuracy_degradation': 0.1,   # 10% accuracy drop\n",
    "            'min_sample_size': 50          # Minimum samples for statistical significance\n",
    "        }\n",
    "    \n",
    "    def simulate_load_test(self, environment: str, model_ver, sample_size: int = 100) -> Dict:\n",
    "        \"\"\"Simulate realistic load testing with performance metrics\"\"\"\n",
    "        print(f\"   üîç Running load test for {environment} environment ({sample_size} requests)...\")\n",
    "        \n",
    "        # Generate test batch\n",
    "        test_batch = self.test_data.sample(n=sample_size, replace=True)\n",
    "        \n",
    "        # Simulate realistic latency variations\n",
    "        base_latency = 45 if environment == \"BLUE\" else 52  # Green slightly slower initially\n",
    "        latencies = []\n",
    "        predictions = []\n",
    "        errors = 0\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i in range(sample_size):\n",
    "            request_start = time.time()\n",
    "            \n",
    "            try:\n",
    "                # Simulate individual prediction\n",
    "                single_row = test_batch.limit(1).offset(i % test_batch.count())\n",
    "                pred_result = model_ver.run(single_row, function_name='PREDICT')\n",
    "                prediction = pred_result.select('PREDICTED_PRICE').collect()[0][0]\n",
    "                predictions.append(prediction)\n",
    "                \n",
    "                # Simulate realistic latency with some randomness\n",
    "                simulated_latency = base_latency + np.random.normal(0, 5) + (i * 0.1)  # Slight degradation over time\n",
    "                latencies.append(max(10, simulated_latency))  # Minimum 10ms\n",
    "                \n",
    "            except Exception as e:\n",
    "                errors += 1\n",
    "                latencies.append(base_latency * 3)  # Error requests take longer\n",
    "                predictions.append(0)  # Default prediction for errors\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        # Calculate ground truth for accuracy assessment\n",
    "        actual_prices = test_batch.select('PRICE').collect()\n",
    "        actual_values = [row[0] for row in actual_prices[:len(predictions)]]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        avg_latency = np.mean(latencies)\n",
    "        p95_latency = np.percentile(latencies, 95)\n",
    "        error_rate = errors / sample_size\n",
    "        \n",
    "        # Calculate MAPE for accuracy\n",
    "        mape = np.mean(np.abs((np.array(actual_values) - np.array(predictions)) / np.array(actual_values))) * 100\n",
    "        \n",
    "        return {\n",
    "            'environment': environment,\n",
    "            'sample_size': sample_size,\n",
    "            'avg_latency': avg_latency,\n",
    "            'p95_latency': p95_latency,\n",
    "            'error_rate': error_rate,\n",
    "            'mape': mape,\n",
    "            'predictions': predictions,\n",
    "            'latencies': latencies,\n",
    "            'total_time': total_time,\n",
    "            'timestamp': datetime.now()\n",
    "        }\n",
    "    \n",
    "    def statistical_comparison(self, blue_metrics: Dict, green_metrics: Dict) -> Dict:\n",
    "        \"\"\"Perform statistical tests to compare blue vs green performance\"\"\"\n",
    "        print(\"   üìä Performing statistical analysis...\")\n",
    "        \n",
    "        # Latency comparison (t-test)\n",
    "        latency_stat, latency_p = stats.ttest_ind(blue_metrics['latencies'], green_metrics['latencies'])\n",
    "        \n",
    "        # Error rate comparison (chi-square test)\n",
    "        blue_errors = int(blue_metrics['error_rate'] * blue_metrics['sample_size'])\n",
    "        green_errors = int(green_metrics['error_rate'] * green_metrics['sample_size'])\n",
    "        \n",
    "        contingency_table = [\n",
    "            [blue_errors, blue_metrics['sample_size'] - blue_errors],\n",
    "            [green_errors, green_metrics['sample_size'] - green_errors]\n",
    "        ]\n",
    "        \n",
    "        chi2_stat, error_rate_p = stats.chi2_contingency(contingency_table)[:2]\n",
    "        \n",
    "        # Effect sizes\n",
    "        latency_effect_size = (green_metrics['avg_latency'] - blue_metrics['avg_latency']) / blue_metrics['avg_latency']\n",
    "        accuracy_effect_size = (green_metrics['mape'] - blue_metrics['mape']) / blue_metrics['mape']\n",
    "        \n",
    "        return {\n",
    "            'latency_significant': latency_p < 0.05,\n",
    "            'latency_p_value': latency_p,\n",
    "            'latency_effect_size': latency_effect_size,\n",
    "            'error_rate_significant': error_rate_p < 0.05,\n",
    "            'error_rate_p_value': error_rate_p,\n",
    "            'accuracy_effect_size': accuracy_effect_size,\n",
    "            'sample_size_adequate': min(blue_metrics['sample_size'], green_metrics['sample_size']) >= self.rollback_triggers['min_sample_size']\n",
    "        }\n",
    "    \n",
    "    def health_check(self, metrics: Dict, baseline_metrics: Dict = None) -> Tuple[bool, List[str]]:\n",
    "        \"\"\"Comprehensive health check with rollback triggers\"\"\"\n",
    "        warnings = []\n",
    "        is_healthy = True\n",
    "        \n",
    "        # Error rate check\n",
    "        if metrics['error_rate'] > self.rollback_triggers['error_rate_threshold']:\n",
    "            warnings.append(f\"‚ùå Error rate too high: {metrics['error_rate']:.3f} > {self.rollback_triggers['error_rate_threshold']}\")\n",
    "            is_healthy = False\n",
    "        \n",
    "        # Latency degradation check (if baseline available)\n",
    "        if baseline_metrics:\n",
    "            latency_ratio = metrics['avg_latency'] / baseline_metrics['avg_latency']\n",
    "            if latency_ratio > self.rollback_triggers['latency_degradation']:\n",
    "                warnings.append(f\"‚ùå Latency degraded: {latency_ratio:.2f}x > {self.rollback_triggers['latency_degradation']}x\")\n",
    "                is_healthy = False\n",
    "            \n",
    "            # Accuracy degradation check\n",
    "            accuracy_ratio = metrics['mape'] / baseline_metrics['mape']\n",
    "            if accuracy_ratio > (1 + self.rollback_triggers['accuracy_degradation']):\n",
    "                warnings.append(f\"‚ùå Accuracy degraded: MAPE {metrics['mape']:.3f} vs baseline {baseline_metrics['mape']:.3f}\")\n",
    "                is_healthy = False\n",
    "        \n",
    "        if is_healthy:\n",
    "            print(\"   ‚úÖ Health check passed\")\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  Health check failed: {len(warnings)} issues detected\")\n",
    "            for warning in warnings:\n",
    "                print(f\"      {warning}\")\n",
    "        \n",
    "        return is_healthy, warnings\n",
    "    \n",
    "    def log_performance_metrics(self, metrics: Dict):\n",
    "        \"\"\"Log detailed performance metrics to monitoring table\"\"\"\n",
    "        for metric_name, value in [\n",
    "            ('avg_latency', metrics['avg_latency']),\n",
    "            ('p95_latency', metrics['p95_latency']),\n",
    "            ('error_rate', metrics['error_rate']),\n",
    "            ('mape', metrics['mape'])\n",
    "        ]:\n",
    "            self.session.sql(f\"\"\"\n",
    "            INSERT INTO MODEL_PERFORMANCE_METRICS \n",
    "            (MODEL_NAME, ENVIRONMENT, MODEL_VERSION, METRIC_NAME, METRIC_VALUE, SAMPLE_SIZE)\n",
    "            VALUES \n",
    "            ('{self.model_name}', '{metrics['environment']}', '{metrics['environment']}_V{1 if metrics['environment']=='BLUE' else 2}', \n",
    "             '{metric_name}', {value}, {metrics['sample_size']})\n",
    "            \"\"\").collect()\n",
    "    \n",
    "    def log_prediction_requests(self, metrics: Dict, traffic_percentage: float):\n",
    "        \"\"\"Log prediction requests with detailed timing and routing info\"\"\"\n",
    "        for i, (prediction, latency) in enumerate(zip(metrics['predictions'][:10], metrics['latencies'][:10])):\n",
    "            request_id = f\"{uuid.uuid4().hex[:8]}_{metrics['environment']}_{int(traffic_percentage)}\"\n",
    "            \n",
    "            self.session.sql(f\"\"\"\n",
    "            INSERT INTO PREDICTION_REQUESTS \n",
    "            (REQUEST_ID, MODEL_NAME, ENVIRONMENT, MODEL_VERSION, PREDICTION, RESPONSE_TIME_MS)\n",
    "            VALUES \n",
    "            ('{request_id}', '{self.model_name}', '{metrics['environment']}', \n",
    "             '{metrics['environment']}_V{1 if metrics['environment']=='BLUE' else 2}', {prediction}, {latency})\n",
    "            \"\"\").collect()\n",
    "    \n",
    "    def update_traffic_split(self, green_percentage: int):\n",
    "        \"\"\"Update traffic distribution between environments\"\"\"\n",
    "        blue_percentage = 100 - green_percentage\n",
    "        \n",
    "        self.session.sql(f\"\"\"\n",
    "        UPDATE DEPLOYMENT_CONFIG \n",
    "        SET TRAFFIC_PERCENTAGE = {blue_percentage},\n",
    "            IS_ACTIVE = CASE WHEN {blue_percentage} > 0 THEN TRUE ELSE FALSE END\n",
    "        WHERE MODEL_NAME = '{self.model_name}' AND ENVIRONMENT = 'BLUE'\n",
    "        \"\"\").collect()\n",
    "        \n",
    "        self.session.sql(f\"\"\"\n",
    "        UPDATE DEPLOYMENT_CONFIG \n",
    "        SET TRAFFIC_PERCENTAGE = {green_percentage},\n",
    "            IS_ACTIVE = CASE WHEN {green_percentage} > 0 THEN TRUE ELSE FALSE END\n",
    "        WHERE MODEL_NAME = '{self.model_name}' AND ENVIRONMENT = 'GREEN'\n",
    "        \"\"\").collect()\n",
    "    \n",
    "    def advanced_canary_stage(self, green_percentage: int, baseline_metrics: Dict = None) -> Tuple[bool, Dict]:\n",
    "        \"\"\"Execute advanced canary deployment stage with comprehensive testing\"\"\"\n",
    "        print(f\"\\nüöÄ Canary Stage: {100-green_percentage}% Blue, {green_percentage}% Green\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Update traffic split\n",
    "        self.update_traffic_split(green_percentage)\n",
    "        \n",
    "        # Run load tests for both environments (proportional to traffic)\n",
    "        blue_sample_size = max(50, int(100 * (100 - green_percentage) / 100))\n",
    "        green_sample_size = max(50, int(100 * green_percentage / 100)) if green_percentage > 0 else 0\n",
    "        \n",
    "        blue_metrics = self.simulate_load_test(\"BLUE\", self.blue_model, blue_sample_size)\n",
    "        green_metrics = None\n",
    "        \n",
    "        if green_percentage > 0:\n",
    "            green_metrics = self.simulate_load_test(\"GREEN\", self.green_model, green_sample_size)\n",
    "            \n",
    "            # Statistical comparison\n",
    "            if green_percentage >= 10:  # Only compare when sufficient green traffic\n",
    "                stats_results = self.statistical_comparison(blue_metrics, green_metrics)\n",
    "                \n",
    "                print(f\"   üìà Performance Comparison:\")\n",
    "                print(f\"      Blue: {blue_metrics['avg_latency']:.1f}ms avg, {blue_metrics['error_rate']:.3f} error rate, {blue_metrics['mape']:.3f} MAPE\")\n",
    "                print(f\"      Green: {green_metrics['avg_latency']:.1f}ms avg, {green_metrics['error_rate']:.3f} error rate, {green_metrics['mape']:.3f} MAPE\")\n",
    "                \n",
    "                if stats_results['sample_size_adequate']:\n",
    "                    print(f\"   üßÆ Statistical Significance:\")\n",
    "                    print(f\"      Latency difference: {'Significant' if stats_results['latency_significant'] else 'Not significant'} (p={stats_results['latency_p_value']:.4f})\")\n",
    "                    print(f\"      Error rate difference: {'Significant' if stats_results['error_rate_significant'] else 'Not significant'} (p={stats_results['error_rate_p_value']:.4f})\")\n",
    "                    print(f\"      Effect sizes: {stats_results['latency_effect_size']:.2%} latency, {stats_results['accuracy_effect_size']:.2%} accuracy\")\n",
    "        \n",
    "        # Health checks\n",
    "        blue_healthy, blue_warnings = self.health_check(blue_metrics, baseline_metrics)\n",
    "        green_healthy = True\n",
    "        \n",
    "        if green_metrics:\n",
    "            green_healthy, green_warnings = self.health_check(green_metrics, baseline_metrics)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log_performance_metrics(blue_metrics)\n",
    "        self.log_prediction_requests(blue_metrics, 100 - green_percentage)\n",
    "        \n",
    "        if green_metrics:\n",
    "            self.log_performance_metrics(green_metrics)\n",
    "            self.log_prediction_requests(green_metrics, green_percentage)\n",
    "        \n",
    "        # Store metrics history\n",
    "        stage_metrics = {\n",
    "            'stage': green_percentage,\n",
    "            'blue_metrics': blue_metrics,\n",
    "            'green_metrics': green_metrics,\n",
    "            'timestamp': datetime.now()\n",
    "        }\n",
    "        self.metrics_history.append(stage_metrics)\n",
    "        \n",
    "        # Determine if stage passed\n",
    "        stage_passed = blue_healthy and green_healthy\n",
    "        \n",
    "        if stage_passed:\n",
    "            print(f\"   ‚úÖ Stage {green_percentage}% passed all health checks\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Stage {green_percentage}% failed health checks\")\n",
    "        \n",
    "        return stage_passed, stage_metrics\n",
    "\n",
    "# Initialize advanced canary deployment\n",
    "canary_deployer = AdvancedCanaryDeployment(\n",
    "    session=session,\n",
    "    model_name=model_name,\n",
    "    blue_model=blue_model_ver,\n",
    "    green_model=green_model_ver,\n",
    "    test_data=test_df\n",
    ")\n",
    "\n",
    "print(\"üü¢ Starting Advanced Canary Deployment with Comprehensive Testing...\")\n",
    "print(\"üéØ Features: Load Testing, Statistical Analysis, Health Monitoring, Auto-Rollback\")\n",
    "print()\n",
    "\n",
    "# Get baseline metrics from blue environment\n",
    "baseline_metrics = canary_deployer.simulate_load_test(\"BLUE\", blue_model_ver, 100)\n",
    "print(f\"üìä Baseline (Blue) Performance: {baseline_metrics['avg_latency']:.1f}ms avg latency, {baseline_metrics['error_rate']:.3f} error rate, {baseline_metrics['mape']:.3f} MAPE\")\n",
    "\n",
    "# Advanced canary stages with comprehensive testing\n",
    "canary_stages = [5, 10, 25, 50, 75, 100]\n",
    "deployment_successful = True\n",
    "\n",
    "for stage in canary_stages:\n",
    "    stage_passed, stage_metrics = canary_deployer.advanced_canary_stage(stage, baseline_metrics)\n",
    "    \n",
    "    if not stage_passed:\n",
    "        print(f\"üö® CANARY DEPLOYMENT FAILED at stage {stage}%\")\n",
    "        print(\"üîÑ Initiating automatic rollback...\")\n",
    "        canary_deployer.update_traffic_split(0)  # Rollback to 100% blue\n",
    "        deployment_successful = False\n",
    "        break\n",
    "    \n",
    "    # Add realistic monitoring delay\n",
    "    print(f\"   ‚è±Ô∏è  Monitoring stage {stage}% for 2 seconds...\")\n",
    "    time.sleep(2)\n",
    "\n",
    "if deployment_successful:\n",
    "    print(\"\\nüéâ CANARY DEPLOYMENT SUCCESSFUL!\")\n",
    "    print(\"‚úÖ Green environment is now serving 100% traffic\")\n",
    "    print(\"üìä All performance metrics within acceptable thresholds\")\n",
    "else:\n",
    "    print(\"\\n‚ùå CANARY DEPLOYMENT ABORTED\")\n",
    "    print(\"üîµ Rolled back to Blue environment (100% traffic)\")\n",
    "    print(\"üìã Review metrics and address issues before retry\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Emergency Rollback Mechanism\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emergency_rollback(model_name, reason=\"Manual rollback\"):\n",
    "    \"\"\"Instantly rollback to blue environment\"\"\"\n",
    "    print(f\"üö® EMERGENCY ROLLBACK INITIATED: {reason}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Instantly switch all traffic back to blue\n",
    "    session.sql(f\"\"\"\n",
    "    UPDATE DEPLOYMENT_CONFIG \n",
    "    SET TRAFFIC_PERCENTAGE = 100,\n",
    "        IS_ACTIVE = TRUE\n",
    "    WHERE MODEL_NAME = '{model_name}' AND ENVIRONMENT = 'BLUE'\n",
    "    \"\"\")\n",
    "    \n",
    "    session.sql(f\"\"\"\n",
    "    UPDATE DEPLOYMENT_CONFIG \n",
    "    SET TRAFFIC_PERCENTAGE = 0,\n",
    "        IS_ACTIVE = FALSE,\n",
    "        HEALTH_CHECK_STATUS = 'ROLLED_BACK'\n",
    "    WHERE MODEL_NAME = '{model_name}' AND ENVIRONMENT = 'GREEN'\n",
    "    \"\"\")\n",
    "    \n",
    "    rollback_time = (time.time() - start_time) * 1000\n",
    "    \n",
    "    print(f\"‚úÖ Rollback completed in {rollback_time:.0f}ms\")\n",
    "    print(\"üîµ Blue environment is now serving 100% traffic\")\n",
    "    \n",
    "    return rollback_time\n",
    "\n",
    "# Demonstrate rollback capability (ready for emergencies)\n",
    "print(\"üí° Emergency rollback function ready\")\n",
    "print(\"üí° Uncomment the line below to test instant rollback:\")\n",
    "print(\"# rollback_time = emergency_rollback(model_name, 'Demo rollback')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Deployment Status Dashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current deployment status\n",
    "deployment_status = session.sql(f\"\"\"\n",
    "SELECT \n",
    "    MODEL_NAME,\n",
    "    ENVIRONMENT,\n",
    "    MODEL_VERSION,\n",
    "    IS_ACTIVE,\n",
    "    TRAFFIC_PERCENTAGE,\n",
    "    HEALTH_CHECK_STATUS,\n",
    "    DEPLOYMENT_TIME,\n",
    "    DATEDIFF('minute', DEPLOYMENT_TIME, CURRENT_TIMESTAMP()) as MINUTES_DEPLOYED\n",
    "FROM DEPLOYMENT_CONFIG \n",
    "WHERE MODEL_NAME = '{model_name}'\n",
    "ORDER BY ENVIRONMENT\n",
    "\"\"\").to_pandas()\n",
    "\n",
    "print(\"üéõÔ∏è  Current Deployment Status:\")\n",
    "print(\"=\" * 80)\n",
    "for _, row in deployment_status.iterrows():\n",
    "    status_icon = \"üü¢\" if row['IS_ACTIVE'] else \"‚ö´\"\n",
    "    health_icon = \"‚úÖ\" if row['HEALTH_CHECK_STATUS'] == 'HEALTHY' else \"‚ö†Ô∏è\"\n",
    "    \n",
    "    print(f\"{status_icon} {row['ENVIRONMENT']} Environment:\")\n",
    "    print(f\"   Version: {row['MODEL_VERSION']}\")\n",
    "    print(f\"   Traffic: {row['TRAFFIC_PERCENTAGE']}%\")\n",
    "    print(f\"   Health: {health_icon} {row['HEALTH_CHECK_STATUS']}\")\n",
    "    print(f\"   Deployed: {row['MINUTES_DEPLOYED']} minutes ago\")\n",
    "    print()\n",
    "\n",
    "# A/B testing results\n",
    "ab_results = session.sql(f\"\"\"\n",
    "SELECT \n",
    "    ENVIRONMENT,\n",
    "    MODEL_VERSION,\n",
    "    COUNT(*) as REQUEST_COUNT,\n",
    "    AVG(PREDICTION) as AVG_PREDICTION,\n",
    "    AVG(RESPONSE_TIME_MS) as AVG_RESPONSE_TIME\n",
    "FROM PREDICTION_REQUESTS \n",
    "WHERE MODEL_NAME = '{model_name}'\n",
    "GROUP BY ENVIRONMENT, MODEL_VERSION\n",
    "ORDER BY ENVIRONMENT\n",
    "\"\"\").to_pandas()\n",
    "\n",
    "print(\"üìä A/B Testing Results:\")\n",
    "if not ab_results.empty:\n",
    "    print(ab_results.to_string(index=False))\n",
    "else:\n",
    "    print(\"No prediction requests logged yet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Production-Ready Features Summary\n",
    "\n",
    "This blue-green deployment implementation demonstrates several production-ready capabilities:\n",
    "\n",
    "### ‚úÖ **Zero-Downtime Deployments**\n",
    "- Instant traffic switching between environments\n",
    "- No service interruption during model updates  \n",
    "- Rollback completed in milliseconds\n",
    "\n",
    "### ‚úÖ **Comprehensive Health Monitoring**\n",
    "- Automated health checks before deployment\n",
    "- Performance metrics tracking\n",
    "- Response time and prediction quality validation\n",
    "\n",
    "### ‚úÖ **Safe Rollout Strategy**\n",
    "- Canary deployments with gradual traffic shifting\n",
    "- A/B testing capabilities for model comparison\n",
    "- Emergency rollback procedures\n",
    "\n",
    "### ‚úÖ **Enterprise Governance**\n",
    "- Complete audit trail of deployments\n",
    "- Performance metrics logging\n",
    "- Model versioning and tagging\n",
    "\n",
    "### üöÄ **Why This Matters for Snowflake**\n",
    "\n",
    "This pattern showcases Snowflake's advantages over traditional ML platforms:\n",
    "\n",
    "1. **Native Integration**: All deployment logic runs inside Snowflake using SQL and Python\n",
    "2. **Data Locality**: Models, monitoring data, and business data stay in one platform  \n",
    "3. **Scale**: Handles enterprise workloads without complex infrastructure\n",
    "4. **Governance**: Built-in security, compliance, and audit capabilities\n",
    "5. **Cost Efficiency**: Pay-per-query pricing vs. always-on cluster costs\n",
    "\n",
    "### üí° **Enterprise Impact**\n",
    "\n",
    "**Traditional ML Platforms:**\n",
    "- Require separate infrastructure for deployment\n",
    "- Complex data movement between systems\n",
    "- Manual rollback procedures\n",
    "- Limited governance and audit trails\n",
    "\n",
    "**Snowflake ML Platform:**\n",
    "- ‚úÖ Zero infrastructure overhead\n",
    "- ‚úÖ No data movement required  \n",
    "- ‚úÖ Instant rollbacks with complete audit trail\n",
    "- ‚úÖ Enterprise-grade governance built-in\n",
    "\n",
    "This demonstrates that Snowflake isn't just a data warehouse‚Äîit's a **complete ML platform** capable of enterprise-grade production deployments that competitors simply cannot match due to their architectural limitations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Snowflake ML Workshop",
   "language": "python",
   "name": "snowflake-ml-workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
